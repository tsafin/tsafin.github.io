---
layout: article
title: Intersystems Caché - Approaching Community Package Manager - Part II
date: '2014-11-25T17:24:00.002+03:00'
author: Timur Safin
tags:
- package manager
- Intersystems
- Caché
modified_time: '2014-11-25T17:30:06.119+03:00'
categories: blog blogger
blogger_id: tag:blogger.com,1999:blog-1111089994103028505.post-2832494304228969512
blogger_orig_url: http://tsafin.blogspot.com/2014/11/community-package-manager-part-ii.html
---

<blockquote>This is the second part of my long post <a href="/2014/11/community-package-manager-part-i.html">about package managers in various operating systems and language distributions</a>. Now you probably "buy the idea" that convenient package manager and 3<sup>rd</sup>    party code repository is the key factor in establishing of a live and popular ecosystem. In the second part we will discuss the action plan for creating of a package-manager for the Cach&eacute;​ database environment.</blockquote>
<p>​So let try to estimate how much we should implement if we would try to add some basic package management facilities to Cach&eacute; ecosystem? Should we do anything in the kernel, or could it be done as external service? What is the <em>minimum functionality</em>    necessary at the beginning to establish anything resembling package management repository? Which still be useful?</p>
<h3>Format</h3>
<p>1<sup>st</sup>&nbsp;question to answer - what is composing the &ldquo;package&rdquo;? What about simplest ever case - when only Cach&eacute; classes to be deployed? How we keep multiple file types? In the ideal case &ndash; some ZIP container could be
    used, but in the&nbsp; <em>simplest case</em> even the simple XML file, as a Cach&eacute; Studio project export could serve the purpose, because even now we could embed all supported file types (CLS, RTN, INC, CSP, ZEN, CSS, GIF, etc.) to such XML
    export files. Not everything is possible to add to the project using Studio UI, but AFAIK much less restrictions applied if we use the Studio API classes.</p>
<blockquote>Yes XML export is very inefficient, bloated, and although it could handle binary files as base64 encoded, but it would generate large files. For the initial implementation though we could ignore this inefficiency for the moment</blockquote>
<h3>Metadata file</h3>
<p>2<sup>nd</sup>&nbsp;question to answer - what should we put as the metadata info? Certainly there should be &ldquo;dependency information&rdquo; (to make possible recursive install of all dependent packages), but what else?</p>
<p>Here is the example of metadata information from some abstract CPAN module using <em>ExtUtils::AutoInstall</em> package functions, which is not usually part of distribution, but one has handy facility for dependency tracking:</p> <pre class="brush: perl"><br /><p>use inc::Module::Install;<br /><br /> name 'Joe-Hacker';<br /> abstract 'Perl Interface to Joe Hacker';<br /> author 'Joe Hacker &lt;joe@hacker.org&gt;';<br /> include 'Module::AutoInstall';<br /><br /> requires 'Module0'; # mandatory modules<br /><br /> feature 'Feature1',<br /> -default =&gt; 0,<br /> 'Module2' =&gt; '0.1';<br /><br /> auto_install(<br /> make_args =&gt; '--hello', # option(s) for CPAN::Config<br /> force =&gt; 1, # pseudo-option to force install<br /> do_once =&gt; 1, # skip previously failed modules<br /> );<br /><br /><br /> WriteAll;<br /></pre>
<p>Here is the example of NPM package dependencies description:</p> <pre class="brush: javascript"><br />{ "dependencies" :<br /> { "foo" : "1.0.0 - 2.9999.9999"<br /> , "bar" : "&gt;=1.0.2 &lt;2.1.2"<br /> , "qux" : "&lt;1.0.0 || &gt;=2.3.1 &lt;2.4.5 || &gt;=2.5.2 &lt;3.0.0"<br /> , "asd" : "http://asdf.com/asdf.tar.gz"<br /> , "til" : "~1.2"<br /> , "elf" : "~1.2.3"<br /> , "lat" : "latest"<br /> , "dyl" : "file:../dyl"<br /> }<br />}<br /></pre>
<p>As a rough approximation, we could start with&nbsp;<a href="https://www.npmjs.org/doc/files/package.json.html">JSON format used by the NPM packages</a>. However, for the simplicity sake, before we have better JSON support in the kernel, we could start
    with XML metadata file information.</p>
<blockquote>Honestly, I hate XML, but let face it - XML and JSON are quite interchangeable, and all about the same, they are 2 different way to serialize hierarchical info. So whatever is described in JSON, could be similarly described in XML, and vice versa.</br>
    Once we have better JSON support in the product, we could easily switch the gears, and use JSON instead of XML for metadata information file. </blockquote>
<h3>Dependency on system classes</h3>
<p>When we are talking about dependencies on some classes there is interesting problem to address - how to mark dependency on some &ldquo;built-in&rdquo; Cach&eacute;/Ensemble/HealthShare/TrakCare class(es), which may have been introduced with some particular
    version? And in general - how to denote dependency on anything from %CACHELIB and similar system database?</p>
<p>For simplicity matter (in the initial implementation) we may just ignore that problem, and if deployed extra class will reference to anything of system database then just assume it&rsquo;s just there.</p>
<p>In the ideal case we should have facilities to require dependency on some particular version (i.e. &ldquo;&gt;2014.1&rdquo;) of particular product (&ldquo;Cache&rdquo;, &ldquo;Ensemble&rdquo;, &ldquo;HealthShare&rdquo;, &ldquo;EM&rdquo;, etc.) or even
    some particular package installed (&ldquo;iKnow&rdquo;, &ldquo;SetAnalysis&rdquo;, etc) This is too early though at the moment to try to invent some definitive mechanism, so we may leave this question unanswered.</p>
<h3>Cross-platform binary modules</h3>
<p>CPAN would not get so much success if there would be no way to distribute packages, which are partially implemented in C, and part in Perl. So for calling to some mission critical, highly optimized code, or as a wrappers for sokme externally available
    C/C++ library. In Perl they have <a href="http://perldoc.perl.org/perlxstut.html">XS API facilities</a> which allows you to call C code from Perl module, and in reverse. If you would look into the implementation details you would quickly realize that
    XS is modelled very similar to Cach&eacute; callout - similarly as in our case, there is no&nbsp;<em>simple</em>&nbsp;<em>and direct&nbsp;</em>wayto call any C/C++ API, you have to write wrapper to call it. But dislike to callout there are available
    a number of service utilities which simplify the process of a wrapper creation, such as:</p>
<ul>
    <li>h2xs preprocessor to generate XS header using the given C header file (well with some limitations);</li>
    <li>xsubpp - preprocessor to convert XS code to pure C code, etc; </ul>
<p>While dealing with callout code from COS we have a little help from the system, and most of the code should be written manually. [Fortunately, now we are allowed to write DLL callouts, and not obliged to statically recompile Cach&eacute; kernel, the situation
    I remember at the early 2000]</p>
<p>There are a couple of rather modern, and relatively convenient approaches to call external C/C++ code from Cach&eacute; kernel:</p>
<ul>
    <li>Builtin FFI mechanism used, for example, by iKnow libraries;</li>
    <li>Or <a href="https://github.com/intersystems-ru/cna">CNA (Cach&eacute; Native Access) callout wrapper</a>&nbsp;which uses LibFFI mechanism for easy calling of&nbsp;<em>any&nbsp;</em>C-runtime function from the COS code;</li>
</ul>
<blockquote>From the practical prospective though, taking into account multiple Cach&eacute platforms we should handle equally well (Windows, Linux, Mac OS X, oreven VMS), and the fact that these both FFI (foreign-function interfaces) are not yet officially supported,
    I should admit that they both are not ready yet, and could not be recommended as a way to handle deployment of mixed C/COS packages. Now it&rsquo;s not a big issue, but eventually, once we will go to cross-platform with binary packages we should revisit
    this topic.</blockquote>
<h3>Unit Testing</h3>
<p>CPAN example showed us yet another good practice, which may positively affect the maturity and stability of 3<sup>rd</sup>&nbsp;party eco-system &ndash; built-in testing support. Each popular Perl package had built-in set of unit-test, which supposed
    to be run after compilation completed and before installation happen. If there this unit-testing is not passed for the target system then installation will not happen.</p>
<p>For simplicity sake we may ignore unit-testing support in the 1st implementation, but once it will evolve to the binary package format (i.e. ZIP) and binary modules support added &ndash; then testing should become required step before installation.</p>
<h3>Command-line access</h3>
<p>User experience is a key factor here - if this system would be inconvenient to use then there is big chance to stay unnoticed. To be useful for COS developers community here we supposed to handle &ldquo;package installations&rdquo; both directions:</p>
<ul>
    <li>be it invoked from COS shell, via simple package-manager shell `do ^CPM`</li>
    <li>or from command-line, i.e. `cpm install DeepSee-Mobile`</li>
</ul>
<blockquote>From practical point of view they should be interchangeable and provide the same side-effect for each operation. But having CLI access to package manager is important for administrators due to scripting needs.</br> <em>In the longer term, once infrastructure is established and mature enough there should be developed GUI wrapper for package manipulations (say, callable from SMP), but GUI is not required at the 1<sup>st</sup> step.</em></blockquote>
<h3>Mirroring and CDN</h3>
<p>In 199x-200x years each package management system faced yet another problem, they had to address separately - how to make their repository respond fast, and preferably from geo-optimized mirror location? And while we are at this topic - what about that
    mirror system should be DDoS resistant at the same time? Such &ldquo;old school&rdquo; software repositories usually relied on community power to deploy huge network of geo-spread mirrors (CPAN, CTAN, Debian, etc.). They are still using the same approach,
    and still have multiple mirrors spread over the planet, but today we have easier soluion to this same problem.</p>
<p>Today there is available a cheap facility of CDN providers. If we need to just host some set of static binary files then CDN is just &ldquo;that doctor ordered&rdquo;. I have no idea who is the best selection for our scenario: whether it will be some
    generic VM-hosting provider like Amazon or Azure, or, may be, we would need to select between&nbsp;<a href="http://aws.amazon.com/ru/cloudfront/">Amazon CloudFront</a>, or&nbsp;<a href="https://www.maxcdn.com/">MaxCDN</a>&nbsp;or anything similar.
    Anything of mentioned is easy to handle nowadays, and not require any extra mirroring effort from the community.</p>
<blockquote>If you have any prior experience with CDN, and have strong preference on something, please provide us advice - we will be curios to know any details. </blockquote>
<h1>Final words</h1>
<p>This is my simple take on the apparent problem of missing convenient repository for 3<sup>rd</sup> party components used in Cach&eacute; database problem. They are either hard to find, or hard to install, or unmaintained, or all at once. We need more
    utilities, more classes available, and more developers involved in the ecosystem. Central repository like CPAN could be a trigger point in changing the scenario of how an average Joe "the COS developer" develops their new solutions.</p>
<p>I hope it's clear now that package manager might be doable right now, even with current database platform support, and could be done in reasonable amount of time. So...</p>
<blockquote>So who is wanting to participate? Do we have community demand here?</blockquote>